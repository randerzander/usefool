# Configuration for the Discord bot
# This file allows you to configure which models are used for different purposes
# and bot behavior settings

# Auto-restart when file changes are detected (default: true)
# Set to false to disable automatic restart on code changes
auto_restart: true

# Base URL for OpenAI-compatible API
# OpenRouter:
#base_url: "https://openrouter.ai/api/v1/chat/completions"
# NVIDIA API:
# base_url: "https://integrate.api.nvidia.com/v1/chat/completions"
# Local llama-cpp server:
base_url: "http://localhost:8080/v1/chat/completions"

# Environment variable name containing the API key
# Set to null or omit for services that don't require authentication
api_key_env: "OPENROUTER_API_KEY"

# Default model for main reasoning and agent operations
# If base_url is localhost, the model will be auto-detected from the API
# Otherwise, specify the model name here
default_model: "nvidia/nemotron-3-nano-30b-a3b"
#default_model: "Qwen3-VL-30B-A3B-Instruct-UD-Q6_K_XL"

# Model parameters (optional - comment out to use model defaults)
# temperature: 1
# top_p: 1
# max_tokens: 16384

# Enable thinking mode for compatible models
# When enabled, adds reasoning_effort parameter to chat completions
# Supported by models like: o1, o1-mini, o1-preview, deepseek-reasoner
enable_thinking: false

# System prompt for the agent
system_prompt: "You are Usefool, a sloppy clanker. Use the available tools and inject some punny witticism. Never mention puns. Never thank the user or offer additional help. If there are errors, always reply with the full trace"

# Model for image captioning with vision language model
# Available models: amazon/nova-lite-v1, qwen/qwen-2-vl-72b-instruct, etc.
image_caption_model: "nvidia/nemotron-nano-12b-v2-vl:free"

# Model for code generation and editing
coding_model: "mistralai/devstral-2512:free"
